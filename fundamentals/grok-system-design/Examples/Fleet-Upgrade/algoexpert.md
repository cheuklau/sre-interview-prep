# Code Deployment

## Functional Requirements

- System to repeatedly build and deploy code to hundreds of thousands of servers
- Sercers across 5-10 regioons
- Building code will involve grabbing snapshots of code using commit SHAs
- Building code will take up to 15 minutes
- Size of binaries of up to 10GB
- Entire process take at most 30 minutes
- Each build ends in SUCCESS or FAILURE
- We care abouot availability (2 to 3 nines)

## Coming up with a Plan

- Two clear sub-ssytems
    1. Build system that builds code into binaries
    2. Deployment system that deploys binaries to machines

## Build System - Overview

- Jobs get added to a queue where each job has a commit identifier (SHA identifier)
- Pool of servers (workers) are going to handle building these jobs
- Each worker will repeatedly take jobs off the queue in a FIFO manner (no prioritization for now)
- Write resulting binaries to blob storage e.g., S3
- Blob storage makes sense since binaries are just blobs of data

## Build System - Job Queue

- Naive design is to put job queue in memory
- This implementation is problematic because we could lose state of jobs (queued jobs and past jobs)
- Better off implementing queue in SQL database

## Build System - SQL Job Queue

- `jobs` table where every record represents a job
- Use record-creation timestamps as queue's ordering mechanism
    * `id`: ID of job, autogenerated
    * `created_at`: timestamp of creation
    * `commit_sha`: string of commit SHA
    * `name`: pointer ot job's eventual binary in blob storage
    * `status`: QUEUED, RUNNING, SUCCEEDED, FAILED
- Implement dequeueing mechanism by looking at oldest `creation_timestamp` with a QUEUED status

## Build System - Concurrency

- ACID transactions make it safe for potentially hundreds of workers grabbing jobs off the queue without unintentionally running same job twice
```
BEGIN TRANSACTION;
SELECT * FROM jobs_table WHERE status = 'QUEUED' ORDER BY created_at ASC LIMIT 1;
// if there is none, then we rollback
UPDATE jobs_table SET status = 'RUNNING' where id = id from previous query;
COMMIT;
```
- All workers will be running this transcation every so often to dequeue the next job
- If we assume that we will have 100 workers sharing same queue, we will have 100/5=20 reads per second which is easy to handle for SQL
    * Note: assuming each worker dequeues every 5 seconds

## Build System - Lost Jobs

- What if there is a network partition with our workers or one of our workers die mid-build?
- Job may remain in RUNNING state forever
- Use extra column in job called `last_heartbeat`
    * This will be updated in a heartbeat fashion by worker where worker updates row every 3-5 minutes to let us know job is still running
- Separate service that polls the tabke every 5 minutes, checks all RUNNING joobs and if `last_heartbeat` is longer than 2 heartbeats ago then something is wrong and service can be reset too QUEUED
```
UPDATE jobs_table SET status = 'QUEUED' WHERE
status = 'RUNNING' AND
last_heartbeat < NOW() - 10 minutes
```

## Build System - Scale Estimation

- Previously assumed we would have 100 workers which made SQL database queue able to handle expected load
- Back of envelope math shows a single worker can run 4 jobs per hour (builds can take up to 15 mintues) which si 100 jobs per day
- If we have 5000-10000 builds per day then we would need 50-100 workers
- System should scale horizontally fairly easily so we can automatically add or remove workers based on load

## Build System - Storage

- When worker completes a build, it stores binary in blob storage before updating relevant row in `jobs` table
- Ensures binary is available before it is marked as SUCCEEDED
- Want to use regional storage

## Deployment System - General Overview

- Want actual deployment system to allow foor very fast distribution of 10GB binaries to hundreds of thousands of servers across global regioons
- Wants some service that tells us when a binary has been replicated in all regions
- Anoother service that can serve as source of truth for what binary shooould currently be run on all machines
- Peer-to-peer-network design foor actual machines across the world

## Deployment system - replication-status service

- Service that continuously checks all regional buckets and aggregates replication status for successful builds
- Once a binary has been replicated across all regions, service updates a separate SQL database with rows containing name of binary and a replicatioon status
- Once binary has a complete replication_status, it is officially deployable

## Deployment system - block distribution

- Sequential download from each server of a 10GB file will be slow
- Instead we want all of oour regional clusters to behave as peer-to-peer networks

## Deployment system - trigger

- Each regional cluster will have a key-value store holding config for that cluster about what builds should be running on that cluster
- Also have a global key-value store
- When engineer clicks Deploy build B1 button:
    1. Global key-value store's build_version gets updated
    2. Regional key-value stores will be continuously polling global key-value store for updates to the build_versioon and will update themselves
    3. Machines in the clusters/regions will poll relevant regional key-value store and when build_version changes, they will try to fetch that build from P2P network and run the binary